{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Fk0y1fmoZlD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use this data to train and perfect your model:\n",
        "df = pd.read_csv('train.csv')"
      ],
      "metadata": {
        "id": "4xo5O-cq3QAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Once your model is ready, generate predictions\n",
        "# using these features\n",
        "test = pd.read_csv('test.csv')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "WUjGCXDe37Ex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# and store your predictions in a file\n",
        "# named `submission.csv`\n",
        "# has to have this format:\n",
        "pd.read_csv('sample_submission.csv', nrows=5)"
      ],
      "metadata": {
        "id": "FUr38ByC391w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_csv('sample_submission.csv', nrows=5).values"
      ],
      "metadata": {
        "id": "QtRzR83r4DXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "7hzBfd3m4PwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Data Cleaning\n",
        "# Check for missing values\n",
        "print(\"\\nMissing Values:\\n\", data.isnull().sum())"
      ],
      "metadata": {
        "id": "mXwxue6S4beF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Exploratory Data Analysis (EDA)\n",
        "# Check the data types and unique values for categorical features\n",
        "print(\"\\nData Types:\\n\", data.dtypes)\n",
        "print(\"\\nUnique values in categorical columns:\")\n",
        "for col in data.select_dtypes(include='object').columns:\n",
        "    print(f\"{col}: {data[col].unique()}\")"
      ],
      "metadata": {
        "id": "IwPbbgu04d4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize correlations (for numerical features)\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(data.corr(), annot=True, cmap='coolwarm')\n",
        "plt.title(\"Correlation Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xyxepaMc4gjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the distribution of the target variable (assuming a column like 'is_canceled')\n",
        "if 'is_canceled' in data.columns:\n",
        "    sns.countplot(x='is_canceled', data=data)\n",
        "    plt.title(\"Cancellation Distribution\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "1p4JDr5CEQaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Feature Engineering\n",
        "# Encode categorical variables\n",
        "categorical_cols = data.select_dtypes(include='object').columns\n",
        "label_encoders = {}\n",
        "for col in categorical_cols:\n",
        "    label_encoders[col] = LabelEncoder()\n",
        "    data[col] = label_encoders[col].fit_transform(data[col])"
      ],
      "metadata": {
        "id": "cK7y3PJMETNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split features and target\n",
        "target_column = 'is_canceled'  # Replace with your target column\n",
        "X = data.drop(columns=[target_column])\n",
        "y = data[target_column]\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "gLVHPRDgETra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize the numerical features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Step 5: Model Training\n",
        "# Train a Random Forest Classifier\n",
        "rf_model = RandomForestClassifier(random_state=42, n_estimators=100, max_depth=10)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Step 6: Model Evaluation\n",
        "# Predict on the test set\n",
        "y_pred = rf_model.predict(X_test)"
      ],
      "metadata": {
        "id": "jAAPKAJWEYoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate performance\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"\\nAccuracy Score:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "-g2bOJPREfwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Feature Importance (Optional)\n",
        "feature_importances = rf_model.feature_importances_\n",
        "important_features = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})\n",
        "important_features = important_features.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Plot feature importance\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Importance', y='Feature', data=important_features)\n",
        "plt.title(\"Feature Importance\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XwAQQA0vEiMo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}